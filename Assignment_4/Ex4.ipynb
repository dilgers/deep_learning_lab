{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class Data:\n",
    "  def __init__(self):\n",
    "    with h5py.File(\"cell_data.h5\", \"r\") as data:\n",
    "      self.train_images = [data[\"/train_image_{}\".format(i)][:] for i in range(28)]\n",
    "      self.train_labels = [data[\"/train_label_{}\".format(i)][:] for i in range(28)]\n",
    "      self.test_images = [data[\"/test_image_{}\".format(i)][:] for i in range(3)]\n",
    "      self.test_labels = [data[\"/test_label_{}\".format(i)][:] for i in range(3)]\n",
    "    \n",
    "    self.input_resolution = 300\n",
    "    self.label_resolution = 116\n",
    "\n",
    "    self.offset = (300 - 116) // 2\n",
    "\n",
    "  def get_train_image_list_and_label_list(self):\n",
    "    n = random.randint(0, len(self.train_images) - 1)\n",
    "    x = random.randint(0, (self.train_images[n].shape)[1] - self.input_resolution - 1)\n",
    "    y = random.randint(0, (self.train_images[n].shape)[0] - self.input_resolution - 1)\n",
    "    image = self.train_images[n][y:y + self.input_resolution, x:x + self.input_resolution, :]\n",
    "\n",
    "    x += self.offset\n",
    "    y += self.offset\n",
    "    label = self.train_labels[n][y:y + self.label_resolution, x:x + self.label_resolution]\n",
    "    \n",
    "    return [image], [label]\n",
    "\n",
    "  def get_test_image_list_and_label_list(self):\n",
    "    coord_list = [[0,0], [0, 116], [0, 232], \n",
    "                  [116,0], [116, 116], [116, 232],\n",
    "                  [219,0], [219, 116], [219, 232]]\n",
    "    \n",
    "    image_list = []\n",
    "    label_list = []\n",
    "    \n",
    "    for image_id in range(3):\n",
    "      for y, x in coord_list:\n",
    "        image = self.test_images[image_id][y:y + self.input_resolution, x:x + self.input_resolution, :]\n",
    "        image_list.append(image)\n",
    "        x += self.offset\n",
    "        y += self.offset\n",
    "        label = self.test_labels[image_id][y:y + self.label_resolution, x:x + self.label_resolution]\n",
    "        label_list.append(label)\n",
    "    \n",
    "\n",
    "    return image_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uNet(inputData):\n",
    "    conlayer1 = lays.conv2d(inputData, 32, [3, 3], stride=1, padding='VALID')\n",
    "    conlayer1 = lays.conv2d(conlayer1, 32, [3, 3], stride=1, padding='VALID')\n",
    "\n",
    "    conlayer2 = tf.layers.max_pooling2d(conlayer1, [2, 2], 2, padding='VALID')\n",
    "    \n",
    "\n",
    "    conlayer2 = lays.conv2d(conlayer2, 64, [3, 3], stride=1, padding='VALID')\n",
    "    conlayer2 = lays.conv2d(conlayer2, 64, [3, 3], stride=1, padding='VALID')\n",
    "\n",
    "    conlayer3 = tf.layers.max_pooling2d(conlayer2, [2, 2], 2)\n",
    "    \n",
    "\n",
    "    conlayer3 = lays.conv2d(conlayer3, 128, [3, 3], stride=1, padding='VALID')\n",
    "    conlayer3 = lays.conv2d(conlayer3, 128, [3, 3], stride=1, padding='VALID')\n",
    "\n",
    "    conlayer4 = tf.layers.max_pooling2d(conlayer3, [2, 2], 2)\n",
    "    \n",
    "\n",
    "    conlayer4 = lays.conv2d(conlayer4, 256, [3, 3], stride=1, padding='VALID')\n",
    "    conlayer4 = lays.conv2d(conlayer4, 256, [3, 3], stride=1, padding='VALID')\n",
    "\n",
    "    conlayer5 = tf.layers.max_pooling2d(conlayer4, [2, 2], 2)\n",
    "    \n",
    "\n",
    "    conlayer5 = lays.conv2d(conlayer5, 512, [3, 3], stride=1, padding='VALID')\n",
    "    conlayer5 = lays.conv2d(conlayer5, 512, [3, 3], stride=1, padding='VALID')\n",
    "\n",
    "    #?\n",
    "    deconlayer4 = lays.conv2d_transpose(conlayer5, 256, [2, 2], stride=2, padding='VALID')\n",
    "    deconShape4 = deconlayer4.get_shape().as_list()\n",
    "    \n",
    "\n",
    "    # --   x   --\n",
    "    #   |     |\n",
    "    #   dA   dB\n",
    "    #\n",
    "    #   y\n",
    "    #\n",
    "    #   dC   dD\n",
    "    #   |     |\n",
    "    # --       --\n",
    "    conShape4 = conlayer4.get_shape().as_list()\n",
    "    dA = int(round(0.5 * (conShape4[1]-deconShape4[1])))\n",
    "    dC = int(round(0.5 * (conShape4[2]-deconShape4[2])))\n",
    "    dB = conShape4[1]-dA\n",
    "    dD = conShape4[2]-dC\n",
    "\n",
    "    conlayer4 = conlayer4[0:conShape4[0], dA:dB, dC:dD, 0:conShape4[3]]\n",
    "    shape = conlayer4.get_shape()\n",
    "    conlayer4 = tf.reshape(conlayer4, shape=[-1,shape[1],shape[2], deconShape4[3]])\n",
    "    deconlayer4 = tf.concat([conlayer4, deconlayer4], 3)\n",
    "\n",
    "\n",
    "    deconlayer4 = lays.conv2d(deconlayer4, 256, [3, 3], stride=1, padding='VALID')\n",
    "\n",
    "    deconlayer4 = lays.conv2d(deconlayer4, 256, [3, 3], stride=1, padding='VALID')\n",
    "\n",
    "    #?\n",
    "    deconlayer3 = lays.conv2d_transpose(deconlayer4, 128, [2, 2], stride=2, padding='VALID')\n",
    "    deconShape3 = deconlayer3.get_shape().as_list()\n",
    "    \n",
    "    conShape3 = conlayer3.get_shape().as_list()\n",
    "    dA = int(round(0.5 * (conShape3[1]-deconShape3[1])))\n",
    "    dC = int(round(0.5 * (conShape3[2]-deconShape3[2])))\n",
    "    dB = conShape3[1]-dA\n",
    "    dD = conShape3[2]-dC\n",
    "    conlayer3 = conlayer3[0:conShape3[0], dA:dB, dC:dD, 0:conShape3[3]]\n",
    "    shape = conlayer3.get_shape()\n",
    "    conlayer3 = tf.reshape(conlayer3, shape=[-1,shape[1],shape[2], deconShape3[3]])\n",
    "    deconlayer3 = tf.concat([conlayer3, deconlayer3], 3)\n",
    "\n",
    "\n",
    "    deconlayer3 = lays.conv2d(deconlayer3, 128, [3, 3], stride=1, padding='VALID')\n",
    "\n",
    "    deconlayer3 = lays.conv2d(deconlayer3, 128, [3, 3], stride=1, padding='VALID')\n",
    "\n",
    "    #?\n",
    "    deconlayer2 = lays.conv2d_transpose(deconlayer3, 64, [2, 2], stride=2, padding='VALID')\n",
    "    deconShape2 = deconlayer2.get_shape().as_list()\n",
    "    \n",
    "    conShape2 = conlayer2.get_shape().as_list()\n",
    "    dA = int(round(0.5 * (conShape2[1]-deconShape2[1])))\n",
    "    dC = int(round(0.5 * (conShape2[2]-deconShape2[2])))\n",
    "    dB = conShape2[1]-dA\n",
    "    dD = conShape2[2]-dC\n",
    "    conlayer2 = conlayer2[0:conShape2[0], dA:dB, dC:dD, 0:conShape2[3]]\n",
    "    shape = conlayer2.get_shape()\n",
    "    conlayer2 = tf.reshape(conlayer2, shape=[-1,shape[1],shape[2], deconShape2[3]])\n",
    "    deconlayer2 = tf.concat([conlayer2, deconlayer2], 3)\n",
    "\n",
    "\n",
    "    deconlayer2 = lays.conv2d(deconlayer2, 64, [3, 3], stride=1, padding='VALID')\n",
    "\n",
    "    deconlayer2 = lays.conv2d(deconlayer2, 64, [3, 3], stride=1, padding='VALID')\n",
    "\n",
    "    #?\n",
    "    deconlayer1 = lays.conv2d_transpose(deconlayer2, 32, [2, 2], stride=2, padding='VALID')\n",
    "    deconShape1 = deconlayer1.get_shape().as_list()\n",
    "    \n",
    "    conShape1 = conlayer1.get_shape().as_list()\n",
    "    dA = int(round(0.5 * (conShape1[1]-deconShape1[1])))\n",
    "    dC = int(round(0.5 * (conShape1[2]-deconShape1[2])))\n",
    "    dB = conShape1[1]-dA\n",
    "    dD = conShape1[2]-dC\n",
    "    conlayer1 = conlayer1[0:conShape1[0], dA:dB, dC:dD, 0:conShape1[3]]\n",
    "    shape = conlayer1.get_shape()\n",
    "    conlayer1 = tf.reshape(conlayer1, shape=[-1,shape[1],shape[2], deconShape1[3]])\n",
    "    deconlayer1 = tf.concat([conlayer1, deconlayer1], 3)\n",
    "\n",
    "\n",
    "    deconlayer1 = lays.conv2d(deconlayer1, 32, [3, 3], stride=1, padding='VALID')\n",
    "\n",
    "    deconlayer1 = lays.conv2d(deconlayer1, 32, [3, 3], stride=1, padding='VALID')\n",
    "\n",
    "    net = lays.conv2d(deconlayer1, 2, [1, 1], stride=1, padding='VALID', activation_fn=None)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 1\n",
    "\n",
    "x = tf.placeholder(tf.float32, (None, 300, 300, 1))\n",
    "netOut = uNet(x)\n",
    "\n",
    "y = tf.placeholder(tf.int32, [None, 116, 116])\n",
    "#yTensor = tf.reshape(y, shape=[-1, 116, 116, 1])\n",
    "#yTensor1 = tf.cast(yTensor, tf.int32)\n",
    "#yTensor2 = tf.one_hot(yTensor1, 2)\n",
    "\n",
    "#loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=yTensor2, logits=netOut))\n",
    "\n",
    "yResh = tf.reshape(y, [batchSize*116*116])\n",
    "yHot=tf.one_hot(yResh,2)\n",
    "\n",
    "netOutResh = tf.reshape(netOut, [batchSize*116*116, 2])\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=yHot, logits=netOutResh))\n",
    "\n",
    "opt = tf.train.AdamOptimizer(0.0001, 0.95, 0.99).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuray(label, predict):\n",
    "    correct = np.sum(predict == label[1][0])\n",
    "    false = np.sum(predict != label[1][0])\n",
    "    total = predict.shape[0] * predict.shape[1]\n",
    "    return correct / (total + false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxIter = 40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainLoss = []\n",
    "TrainAcc = []\n",
    "TestAcc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 63.1s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "for idx in range(maxIter):\n",
    "    batch = data.get_train_image_list_and_label_list()\n",
    "    \n",
    "    #opt.run(feed_dict={x: batch[0], y: batch[1]})\n",
    "    _, c = sess.run([opt, loss], feed_dict={x: batch[0], y: batch[1]})\n",
    "    TrainLoss.append(c)\n",
    "   \n",
    "   \n",
    "    \n",
    "    if i % 200 == 0:\n",
    "        reconstImg = sess.run([netOut], feed_dict={x: batch[0], y: batch[1]})[0][0]\n",
    "        reconstImg=np.argmax(reconstImg, axis=-1)\n",
    "        bachArr = np.array(batch[1][0])\n",
    "\n",
    "        TrainLoss.append(c)\n",
    "        TrainAcc.append(accuray(bachArr, reconstImg))\n",
    "        \n",
    "        \n",
    "            \n",
    "        #test\n",
    "        imag, label = data.get_test_image_list_and_label_list()\n",
    "        testAccuracy=0.0\n",
    "        for j in range(len(label)):\n",
    "            reconstImg = sess.run([netOut], feed_dict={x: batch[0], y: batch[1]})[0][0]\n",
    "            reconstImg=np.argmax(reconstImg, axis=-1)\n",
    "            bachArr = np.array(batch[1][0])\n",
    "            testAccuracy += accuray(bachArr, reconstImg)            \n",
    "        \n",
    "        testAccuracy = testAccuracy/len(label)\n",
    "        TestAcc.append(testAccuracy)\n",
    "        \n",
    "\n",
    "t1 = time.time()\n",
    "print('Time: {:.1f}s'.format(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116\n",
      "116\n",
      "2\n",
      "116\n",
      "116\n",
      "(116, 116)\n",
      "116\n",
      "116\n",
      "13056\n",
      "400\n",
      "13456\n",
      "0.942263279446\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADHNJREFUeJzt3V/onYV9x/H3Z0mt07KauBHSxM0UQ4sUOuXHUOxF0Zap\nK9WLUpRCwxBy0632D7S6Xe1SKLUWRBbU1g2xdlZm8KLFpo7tZplJLRqNNmmdmpAYS9WOXil+d3Ge\ndL+vJs3P3/kb937B4ZznOf++PPn55nmec+SkqpCk4/5g3gNIWixGQVJjFCQ1RkFSYxQkNUZBUmMU\nJDVTiUKSK5M8m+Rgkpum8R6SpiOT/vJSkjXAz4FPAoeAx4Drq+rpib6RpKlYO4XX/AvgYFX9EiDJ\n94BrgJNGIYlfq5Sm71dV9SenetA0Dh82AS8uWz40rGuSbE+yJ8meKcwg6e2eX8mDprGnsCJVtQPY\nAe4pSItkGnsKh4Hzli1vHtZJOg1MIwqPAVuTbElyBnAdsHMK7yNpCiZ++FBVbyT5G+BHwBrg7qp6\natLvI2k6Jv6R5KqG8JyCNAt7q2rpVA/yG42SGqMgqTEKkhqjIKkxCpIaoyCpMQqSGqMgqTEKkhqj\nIKkxCpIaoyCpMQqSGqMgqTEKkhqjIKkxCpIaoyCpMQqSGqMgqTEKkhqjIKkxCpIaoyCpMQqSGqMg\nqTEKkhqjIKlZdRSSnJfk0SRPJ3kqyY3D+vVJHklyYLheN7lxJU3bOHsKbwBfraoLgUuALyS5ELgJ\n2FVVW4Fdw7Kk08Sqo1BVR6rqp8Pt/wH2A5uAa4B7hofdA1w77pCSZmci5xSSnA9cBOwGNlTVkeGu\no8CGSbyHpNlYO+4LJHkf8APgS1X1myS/u6+qKkmd5Hnbge3jvr+kyRprTyHJexgF4d6qenBY/VKS\njcP9G4FjJ3puVe2oqqWqWhpnBkmTNc6nDwHuAvZX1TeX3bUT2Dbc3gY8tPrxJM1aqk64d3/qJyYf\nA/4DeBJ4c1j9d4zOK3wf+FPgeeCzVfXrU7zW6oaQ9E7sXcme+aqjMElGQZqJFUXBbzRKak6LKCzC\n3oz0/8VpEQVJs3NaRGH5dx8kTddpEQVJs2MUJDVGQVJjFCQ1RkFSYxQkNUZBUmMUJDVGQVJjFCQ1\nRkFSYxQkNUZBUmMUJDVGQVJjFCQ1RkFSYxQkNUZBUmMUJDVGQVJjFCQ1RkFSYxQkNUZBUjN2FJKs\nSfJ4koeH5S1Jdic5mOT+JGeMP6akWZnEnsKNwP5ly7cAt1bVBcArwA0TeA9JMzJWFJJsBv4KuHNY\nDnA58MDwkHuAa8d5D0mzNe6ewreArwFvDsvnAq9W1RvD8iFg04memGR7kj1J9ow5g6QJWnUUknwK\nOFZVe1fz/KraUVVLVbW02hkkTd7aMZ57GfDpJFcDZwJ/BNwGnJNk7bC3sBk4PP6YkmZl1XsKVXVz\nVW2uqvOB64CfVNXngEeBzwwP2wY8NPaUkmZmGt9T+DrwlSQHGZ1juGsK7yFpSlJV856BJPMfQnr3\n27uSc3h+o1FSYxQkNUZBUmMUJDVGQVJjFCQ1RkFSYxQkNUZBUmMUJDVGQVJjFCQ1RkFSYxQkNUZB\nUmMUJDVGQVJjFCQ1RkFSYxQkNUZBUmMUJDVGQVJjFCQ1RkFSYxQkNUZBUmMUJDVjRSHJOUkeSPJM\nkv1JLk2yPskjSQ4M1+smNayk6Rt3T+E24IdV9WHgo8B+4CZgV1VtBXYNy5JOE6v+Kfok7wd+Bnyw\nlr1IkmeBj1fVkSQbgX+rqg+d4rX8KXpp+qb+U/RbgJeB7yR5PMmdSc4GNlTVkeExR4ENY7yHpBkb\nJwprgYuBO6rqIuC3vOVQYdiDOOFeQJLtSfYk2TPGDJImbJwoHAIOVdXuYfkBRpF4aThsYLg+dqIn\nV9WOqlpaye6MpNlZdRSq6ijwYpLj5wuuAJ4GdgLbhnXbgIfGmlDSTK0d8/l/C9yb5Azgl8BfMwrN\n95PcADwPfHbM95A0Q6v+9GGiQ/jpgzQLU//0QdK7kFGQ1BgFSY1RkNQYBUmNUZDUGAVJjVGQ1BgF\nSY1RkNQYBUmNUZDUGAVJjVGQ1BgFSY1RkNQYBUmNUZDUGAVJjVGQ1BgFSY1RkNQYBUmNUZDUGAVJ\njVGQ1BgFSY1RkNQYBUnNWFFI8uUkTyXZl+S+JGcm2ZJkd5KDSe4ffqZe0mli1VFIsgn4IrBUVR8B\n1gDXAbcAt1bVBcArwA2TGFTSbIx7+LAW+MMka4GzgCPA5cADw/33ANeO+R6SZmjVUaiqw8A3gBcY\nxeA1YC/walW9MTzsELDpRM9Psj3JniR7VjuDpMkb5/BhHXANsAX4AHA2cOVKn19VO6pqqaqWVjuD\npMkb5/DhE8BzVfVyVb0OPAhcBpwzHE4AbAYOjzmjpBkaJwovAJckOStJgCuAp4FHgc8Mj9kGPDTe\niJJmaZxzCrsZnVD8KfDk8Fo7gK8DX0lyEDgXuGsCc0qakVTVvGcgyfyHkN799q7kHJ7faJTUGAVJ\njVGQ1BgFSY1RkNQYBUmNUZDUGAVJjVGQ1BgFSY1RkNQYBUmNUZDUGAVJjVGQ1BgFSY1RkNQYBUmN\nUZDUGAVJjVGQ1BgFSY1RkNQYBUmNUZDUGAVJjVGQ1BgFSc0po5Dk7iTHkuxbtm59kkeSHBiu1w3r\nk+TbSQ4meSLJxdMcXtLkrWRP4bvAlW9ZdxOwq6q2AruGZYCrgK3DZTtwx2TGlDQrp4xCVf078Ou3\nrL4GuGe4fQ9w7bL1/1Qj/wmck2TjpIaVNH2rPaewoaqODLePAhuG25uAF5c97tCwTtJpYu24L1BV\nlaTe6fOSbGd0iCFpgax2T+Gl44cFw/WxYf1h4Lxlj9s8rHubqtpRVUtVtbTKGSRNwWqjsBPYNtze\nBjy0bP3nh08hLgFeW3aYIel0UFW/9wLcBxwBXmd0juAG4FxGnzocAH4MrB8eG+B24BfAk8DSqV5/\neF558eJl6pc9K/nvMcN/lHO1mnMSkt6xvSs5XPcbjZIaoyCpMQqSGqMgqTEKkhqjIKkxCpIaoyCp\nMQqSGqMgqTEKkhqjIKkxCpIaoyCpMQqSGqMgqTEKkhqjIKkxCpIaoyCpMQqSGqMgqTEKkhqjIKkZ\n+wdmJ+RXwG+H60XzxyzeXM60cos417xm+rOVPGghfiEKIMmeRfyx2UWcy5lWbhHnWsSZlvPwQVJj\nFCQ1ixSFHfMe4CQWcS5nWrlFnGsRZ/qdhTmnIGkxLNKegqQFsBBRSHJlkmeTHExy05xmOC/Jo0me\nTvJUkhuH9euTPJLkwHC9bg6zrUnyeJKHh+UtSXYP2+v+JGfMYaZzkjyQ5Jkk+5NcOu9tleTLw7/d\nviT3JTlzHtsqyd1JjiXZt2zdCbdNRr49zPdEkounPd+pzD0KSdYAtwNXARcC1ye5cA6jvAF8taou\nBC4BvjDMcROwq6q2AruG5Vm7Edi/bPkW4NaqugB4BbhhDjPdBvywqj4MfHSYb27bKskm4IvAUlV9\nBFgDXMd8ttV3gSvfsu5k2+YqYOtw2Q7cMYP5fr+qmusFuBT40bLlm4GbF2Cuh4BPAs8CG4d1G4Fn\nZzzHZkZ/RJcDDwNh9MWXtSfafjOa6f3AcwznpJatn9u2AjYBLwLrGX0p72HgL+e1rYDzgX2n2jbA\nPwLXn+hx87rMfU+B//vHPO7QsG5ukpwPXATsBjZU1ZHhrqPAhhmP8y3ga8Cbw/K5wKtV9cawPI/t\ntQV4GfjOcFhzZ5KzmeO2qqrDwDeAF4AjwGvAXua/rY472bZZuL//RYjCQknyPuAHwJeq6jfL76tR\nymf2cU2STwHHqmrvrN5zhdYCFwN3VNVFjL6i3g4V5rCt1gHXMArWB4Czefsu/EKY9bZ5pxYhCoeB\n85Ytbx7WzVyS9zAKwr1V9eCw+qUkG4f7NwLHZjjSZcCnk/w38D1GhxC3AeckOf7/rcxjex0CDlXV\n7mH5AUaRmOe2+gTwXFW9XFWvAw8y2n7z3lbHnWzbLMzf/3GLEIXHgK3DWeIzGJ0c2jnrIZIEuAvY\nX1XfXHbXTmDbcHsbo3MNM1FVN1fV5qo6n9F2+UlVfQ54FPjMPGYa5joKvJjkQ8OqK4CnmeO2YnTY\ncEmSs4Z/y+MzzXVbLXOybbMT+PzwKcQlwGvLDjPmY54nNJadXLka+DnwC+Dv5zTDxxjt0j0B/Gy4\nXM3oGH4XcAD4MbB+TvN9HHh4uP1B4L+Ag8C/AO+dwzx/DuwZtte/Auvmva2AfwCeAfYB/wy8dx7b\nCriP0XmN1xntVd1wsm3D6MTx7cPf/pOMPj2Z+d/X8ovfaJTULMLhg6QFYhQkNUZBUmMUJDVGQVJj\nFCQ1RkFSYxQkNf8LyKVJDGER4gcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f24a19353c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f24a1716fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch = data.get_train_image_list_and_label_list()\n",
    "reconstImg = sess.run([netOut], feed_dict={x: batch[0], y: batch[1]})[0][0]\n",
    "\n",
    "\n",
    "#print(len(batch[1][0][0]))\n",
    "#print(len(reconstImg[0][0]))\n",
    "\n",
    "\n",
    "\n",
    "#train_accuracy = (np.sum(reconstImg))/(reconstImg.shape[0]-np.sum(reconstImg))\n",
    "#print(train_accuracy)\n",
    "#tf.metrics.mean_iou(batch[1], reconstImg, 2)\n",
    "\n",
    "\n",
    "\n",
    "#print(reconstImg.shape)\n",
    "#reconstImg=np.argmax(reconstImg, axis=-1)\n",
    "#print(reconstImg.shape)\n",
    "\n",
    "#print(np.sum(reconstImg == batch[1]))\n",
    "print(len(reconstImg))\n",
    "print(len(reconstImg[0]))\n",
    "print(len(reconstImg[0][0]))\n",
    "\n",
    "reconstImg=np.argmax(reconstImg, axis=-1)\n",
    "print(len(reconstImg))\n",
    "print(len(reconstImg[0]))\n",
    "\n",
    "print(reconstImg.shape)\n",
    "#print(len(batch[1]))\n",
    "print(len(batch[1][0]))\n",
    "print(len(batch[1][0][0]))\n",
    "\n",
    "bachArr = np.array(batch[1][0])\n",
    "bachArr.shape\n",
    "\n",
    "correct = np.sum(reconstImg == batch[1][0])\n",
    "false = np.sum(reconstImg != batch[1][0])\n",
    "total = reconstImg.shape[0] * reconstImg.shape[1]\n",
    "\n",
    "print(correct)\n",
    "print(false)\n",
    "print(total)\n",
    "\n",
    "acc = correct / (total + false)\n",
    "print(acc)\n",
    "#for ixd in range(116):\n",
    "plt.figure(0)\n",
    "plt.imshow(reconstImg, cmap='gray')\n",
    "plt.figure(1)\n",
    "plt.imshow(batch[1][0], cmap='gray')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
